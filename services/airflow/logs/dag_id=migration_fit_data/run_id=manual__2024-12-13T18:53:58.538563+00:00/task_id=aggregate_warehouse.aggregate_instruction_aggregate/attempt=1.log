[2024-12-13T18:55:00.069+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-12-13T18:55:00.135+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: migration_fit_data.aggregate_warehouse.aggregate_instruction_aggregate manual__2024-12-13T18:53:58.538563+00:00 [queued]>
[2024-12-13T18:55:00.158+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: migration_fit_data.aggregate_warehouse.aggregate_instruction_aggregate manual__2024-12-13T18:53:58.538563+00:00 [queued]>
[2024-12-13T18:55:00.159+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-12-13T18:55:00.182+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): aggregate_warehouse.aggregate_instruction_aggregate> on 2024-12-13 18:53:58.538563+00:00
[2024-12-13T18:55:00.212+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=4058) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-12-13T18:55:00.214+0000] {standard_task_runner.py:63} INFO - Started process 4066 to run task
[2024-12-13T18:55:00.218+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'migration_fit_data', 'aggregate_warehouse.aggregate_instruction_aggregate', 'manual__2024-12-13T18:53:58.538563+00:00', '--job-id', '471', '--raw', '--subdir', 'DAGS_FOLDER/elt_migrate.py', '--cfg-path', '/tmp/tmpta0zmwp6']
[2024-12-13T18:55:00.223+0000] {standard_task_runner.py:91} INFO - Job 471: Subtask aggregate_warehouse.aggregate_instruction_aggregate
[2024-12-13T18:55:00.361+0000] {task_command.py:426} INFO - Running <TaskInstance: migration_fit_data.aggregate_warehouse.aggregate_instruction_aggregate manual__2024-12-13T18:53:58.538563+00:00 [running]> on host 1fe973f28a1c
[2024-12-13T18:55:00.547+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='migration_fit_data' AIRFLOW_CTX_TASK_ID='aggregate_warehouse.aggregate_instruction_aggregate' AIRFLOW_CTX_EXECUTION_DATE='2024-12-13T18:53:58.538563+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-13T18:53:58.538563+00:00'
[2024-12-13T18:55:00.550+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-12-13T18:55:00.572+0000] {hive.py:475} INFO - USE `default`
[2024-12-13T18:55:00.592+0000] {hive.py:475} INFO - CREATE NAMESPACE IF NOT EXISTS iceberg.aggr_warehouse
[2024-12-13T18:55:00.602+0000] {hive.py:475} INFO - DROP TABLE IF EXISTS iceberg.aggr_warehouse.instruction_aggregate
[2024-12-13T18:55:00.681+0000] {hive.py:475} INFO - 
    CREATE OR REPLACE TABLE iceberg.aggr_warehouse.instruction_aggregate
    USING parquet
    AS
    SELECT
        inf.instruction_id,
        c.course_id,
        c.course_name,
        ps.program_id,
        ps.semester_name,
        inf.num_student AS num_students,
        inf.avg_final_score
    FROM
        iceberg.warehouse.instruction_fact inf
    JOIN iceberg.warehouse.course c ON inf.course_id = c.course_id
    JOIN iceberg.warehouse.program_semester ps ON inf.program_semester_id = ps.program_semester_id;
    WHERE 
        inf.instruction_status = 'completed'
    
[2024-12-13T18:55:00.859+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-12-13T18:55:00.859+0000] {taskinstance.py:2905} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 235, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 252, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/tasks/fit_task.py", line 113, in aggregate_into_warehouse
    cursor.execute(FIT_AGGREGATE_TABLES[table]["create_table_command"])
  File "/home/airflow/.local/lib/python3.12/site-packages/pyhive/hive.py", line 481, in execute
    _check_status(response)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyhive/hive.py", line 611, in _check_status
    raise OperationalError(response)
pyhive.exc.OperationalError: TExecuteStatementResp(status=TStatus(statusCode=3, infoMessages=["*org.apache.hive.service.cli.HiveSQLException:Error running query: [PARSE_SYNTAX_ERROR] org.apache.spark.sql.catalyst.parser.ParseException: \n[PARSE_SYNTAX_ERROR] Syntax error at or near 'WHERE': extra input 'WHERE'.(line 17, pos 4)\n\n== SQL ==\n\n    CREATE OR REPLACE TABLE iceberg.aggr_warehouse.instruction_aggregate\n    USING parquet\n    AS\n    SELECT\n        inf.instruction_id,\n        c.course_id,\n        c.course_name,\n        ps.program_id,\n        ps.semester_name,\n        inf.num_student AS num_students,\n        inf.avg_final_score\n    FROM\n        iceberg.warehouse.instruction_fact inf\n    JOIN iceberg.warehouse.course c ON inf.course_id = c.course_id\n    JOIN iceberg.warehouse.program_semester ps ON inf.program_semester_id = ps.program_semester_id;\n    WHERE \n----^^^\n        inf.instruction_status = 'completed'\n    \n:36:35", 'org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$:runningQueryError:HiveThriftServerErrors.scala:43', 'org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation:org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute:SparkExecuteStatementOperation.scala:262', 'org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation:runInternal:SparkExecuteStatementOperation.scala:152', 'org.apache.hive.service.cli.operation.Operation:run:Operation.java:277', 'org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation:org$apache$spark$sql$hive$thriftserver$SparkOperation$$super$run:SparkExecuteStatementOperation.scala:41', 'org.apache.spark.sql.hive.thriftserver.SparkOperation:$anonfun$run$1:SparkOperation.scala:45', 'scala.runtime.java8.JFunction0$mcV$sp:apply:JFunction0$mcV$sp.java:23', 'org.apache.spark.sql.hive.thriftserver.SparkOperation:withLocalProperties:SparkOperation.scala:79', 'org.apache.spark.sql.hive.thriftserver.SparkOperation:withLocalProperties$:SparkOperation.scala:63', 'org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation:withLocalProperties:SparkExecuteStatementOperation.scala:41', 'org.apache.spark.sql.hive.thriftserver.SparkOperation:run:SparkOperation.scala:45', 'org.apache.spark.sql.hive.thriftserver.SparkOperation:run$:SparkOperation.scala:43', 'org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation:run:SparkExecuteStatementOperation.scala:41', 'org.apache.hive.service.cli.session.HiveSessionImpl:executeStatementInternal:HiveSessionImpl.java:484', 'org.apache.hive.service.cli.session.HiveSessionImpl:executeStatement:HiveSessionImpl.java:460', 'jdk.internal.reflect.GeneratedMethodAccessor20:invoke::-1', 'jdk.internal.reflect.DelegatingMethodAccessorImpl:invoke::-1', 'java.lang.reflect.Method:invoke::-1', 'org.apache.hive.service.cli.session.HiveSessionProxy:invoke:HiveSessionProxy.java:71', 'org.apache.hive.service.cli.session.HiveSessionProxy:lambda$invoke$0:HiveSessionProxy.java:58', 'java.security.AccessController:doPrivileged::-2', 'javax.security.auth.Subject:doAs::-1', 'org.apache.hadoop.security.UserGroupInformation:doAs:UserGroupInformation.java:1878', 'org.apache.hive.service.cli.session.HiveSessionProxy:invoke:HiveSessionProxy.java:58', 'com.sun.proxy.$Proxy39:executeStatement::-1', 'org.apache.hive.service.cli.CLIService:executeStatement:CLIService.java:282', 'org.apache.hive.service.cli.thrift.ThriftCLIService:ExecuteStatement:ThriftCLIService.java:453', 'org.apache.hive.service.rpc.thrift.TCLIService$Processor$ExecuteStatement:getResult:TCLIService.java:1557', 'org.apache.hive.service.rpc.thrift.TCLIService$Processor$ExecuteStatement:getResult:TCLIService.java:1542', 'org.apache.thrift.ProcessFunction:process:ProcessFunction.java:38', 'org.apache.thrift.TBaseProcessor:process:TBaseProcessor.java:39', 'org.apache.hive.service.auth.TSetIpAddressProcessor:process:TSetIpAddressProcessor.java:52', 'org.apache.thrift.server.TThreadPoolServer$WorkerProcess:run:TThreadPoolServer.java:310', 'java.util.concurrent.ThreadPoolExecutor:runWorker::-1', 'java.util.concurrent.ThreadPoolExecutor$Worker:run::-1', 'java.lang.Thread:run::-1', "*org.apache.spark.sql.catalyst.parser.ParseException:\n[PARSE_SYNTAX_ERROR] Syntax error at or near 'WHERE': extra input 'WHERE'.(line 17, pos 4)\n\n== SQL ==\n\n    CREATE OR REPLACE TABLE iceberg.aggr_warehouse.instruction_aggregate\n    USING parquet\n    AS\n    SELECT\n        inf.instruction_id,\n        c.course_id,\n        c.course_name,\n        ps.program_id,\n        ps.semester_name,\n        inf.num_student AS num_students,\n        inf.avg_final_score\n    FROM\n        iceberg.warehouse.instruction_fact inf\n    JOIN iceberg.warehouse.course c ON inf.course_id = c.course_id\n    JOIN iceberg.warehouse.program_semester ps ON inf.program_semester_id = ps.program_semester_id;\n    WHERE \n----^^^\n        inf.instruction_status = 'completed'\n    \n:48:13", 'org.apache.spark.sql.catalyst.parser.ParseException:withCommand:parsers.scala:257', 'org.apache.spark.sql.catalyst.parser.AbstractParser:parse:parsers.scala:98', 'org.apache.spark.sql.execution.SparkSqlParser:parse:SparkSqlParser.scala:54', 'org.apache.spark.sql.catalyst.parser.AbstractSqlParser:parsePlan:AbstractSqlParser.scala:68', 'org.apache.spark.sql.catalyst.parser.extensions.IcebergSparkSqlExtensionsParser:parsePlan:IcebergSparkSqlExtensionsParser.scala:126', 'org.apache.spark.sql.SparkSession:$anonfun$sql$5:SparkSession.scala:684', 'org.apache.spark.sql.catalyst.QueryPlanningTracker:measurePhase:QueryPlanningTracker.scala:138', 'org.apache.spark.sql.SparkSession:$anonfun$sql$4:SparkSession.scala:683', 'org.apache.spark.sql.SparkSession:withActive:SparkSession.scala:900', 'org.apache.spark.sql.SparkSession:sql:SparkSession.scala:682', 'org.apache.spark.sql.SparkSession:sql:SparkSession.scala:713', 'org.apache.spark.sql.SparkSession:sql:SparkSession.scala:744', 'org.apache.spark.sql.SQLContext:sql:SQLContext.scala:651', 'org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation:org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute:SparkExecuteStatementOperation.scala:227'], sqlState='42601', errorCode=0, errorMessage="Error running query: [PARSE_SYNTAX_ERROR] org.apache.spark.sql.catalyst.parser.ParseException: \n[PARSE_SYNTAX_ERROR] Syntax error at or near 'WHERE': extra input 'WHERE'.(line 17, pos 4)\n\n== SQL ==\n\n    CREATE OR REPLACE TABLE iceberg.aggr_warehouse.instruction_aggregate\n    USING parquet\n    AS\n    SELECT\n        inf.instruction_id,\n        c.course_id,\n        c.course_name,\n        ps.program_id,\n        ps.semester_name,\n        inf.num_student AS num_students,\n        inf.avg_final_score\n    FROM\n        iceberg.warehouse.instruction_fact inf\n    JOIN iceberg.warehouse.course c ON inf.course_id = c.course_id\n    JOIN iceberg.warehouse.program_semester ps ON inf.program_semester_id = ps.program_semester_id;\n    WHERE \n----^^^\n        inf.instruction_status = 'completed'\n    \n"), operationHandle=None)
[2024-12-13T18:55:00.888+0000] {taskinstance.py:1206} INFO - Marking task as FAILED. dag_id=migration_fit_data, task_id=aggregate_warehouse.aggregate_instruction_aggregate, run_id=manual__2024-12-13T18:53:58.538563+00:00, execution_date=20241213T185358, start_date=20241213T185500, end_date=20241213T185500
[2024-12-13T18:55:00.917+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 471 for task aggregate_warehouse.aggregate_instruction_aggregate (TExecuteStatementResp(status=TStatus(statusCode=3, infoMessages=["*org.apache.hive.service.cli.HiveSQLException:Error running query: [PARSE_SYNTAX_ERROR] org.apache.spark.sql.catalyst.parser.ParseException: \n[PARSE_SYNTAX_ERROR] Syntax error at or near 'WHERE': extra input 'WHERE'.(line 17, pos 4)\n\n== SQL ==\n\n    CREATE OR REPLACE TABLE iceberg.aggr_warehouse.instruction_aggregate\n    USING parquet\n    AS\n    SELECT\n        inf.instruction_id,\n        c.course_id,\n        c.course_name,\n        ps.program_id,\n        ps.semester_name,\n        inf.num_student AS num_students,\n        inf.avg_final_score\n    FROM\n        iceberg.warehouse.instruction_fact inf\n    JOIN iceberg.warehouse.course c ON inf.course_id = c.course_id\n    JOIN iceberg.warehouse.program_semester ps ON inf.program_semester_id = ps.program_semester_id;\n    WHERE \n----^^^\n        inf.instruction_status = 'completed'\n    \n:36:35", 'org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$:runningQueryError:HiveThriftServerErrors.scala:43', 'org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation:org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute:SparkExecuteStatementOperation.scala:262', 'org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation:runInternal:SparkExecuteStatementOperation.scala:152', 'org.apache.hive.service.cli.operation.Operation:run:Operation.java:277', 'org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation:org$apache$spark$sql$hive$thriftserver$SparkOperation$$super$run:SparkExecuteStatementOperation.scala:41', 'org.apache.spark.sql.hive.thriftserver.SparkOperation:$anonfun$run$1:SparkOperation.scala:45', 'scala.runtime.java8.JFunction0$mcV$sp:apply:JFunction0$mcV$sp.java:23', 'org.apache.spark.sql.hive.thriftserver.SparkOperation:withLocalProperties:SparkOperation.scala:79', 'org.apache.spark.sql.hive.thriftserver.SparkOperation:withLocalProperties$:SparkOperation.scala:63', 'org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation:withLocalProperties:SparkExecuteStatementOperation.scala:41', 'org.apache.spark.sql.hive.thriftserver.SparkOperation:run:SparkOperation.scala:45', 'org.apache.spark.sql.hive.thriftserver.SparkOperation:run$:SparkOperation.scala:43', 'org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation:run:SparkExecuteStatementOperation.scala:41', 'org.apache.hive.service.cli.session.HiveSessionImpl:executeStatementInternal:HiveSessionImpl.java:484', 'org.apache.hive.service.cli.session.HiveSessionImpl:executeStatement:HiveSessionImpl.java:460', 'jdk.internal.reflect.GeneratedMethodAccessor20:invoke::-1', 'jdk.internal.reflect.DelegatingMethodAccessorImpl:invoke::-1', 'java.lang.reflect.Method:invoke::-1', 'org.apache.hive.service.cli.session.HiveSessionProxy:invoke:HiveSessionProxy.java:71', 'org.apache.hive.service.cli.session.HiveSessionProxy:lambda$invoke$0:HiveSessionProxy.java:58', 'java.security.AccessController:doPrivileged::-2', 'javax.security.auth.Subject:doAs::-1', 'org.apache.hadoop.security.UserGroupInformation:doAs:UserGroupInformation.java:1878', 'org.apache.hive.service.cli.session.HiveSessionProxy:invoke:HiveSessionProxy.java:58', 'com.sun.proxy.$Proxy39:executeStatement::-1', 'org.apache.hive.service.cli.CLIService:executeStatement:CLIService.java:282', 'org.apache.hive.service.cli.thrift.ThriftCLIService:ExecuteStatement:ThriftCLIService.java:453', 'org.apache.hive.service.rpc.thrift.TCLIService$Processor$ExecuteStatement:getResult:TCLIService.java:1557', 'org.apache.hive.service.rpc.thrift.TCLIService$Processor$ExecuteStatement:getResult:TCLIService.java:1542', 'org.apache.thrift.ProcessFunction:process:ProcessFunction.java:38', 'org.apache.thrift.TBaseProcessor:process:TBaseProcessor.java:39', 'org.apache.hive.service.auth.TSetIpAddressProcessor:process:TSetIpAddressProcessor.java:52', 'org.apache.thrift.server.TThreadPoolServer$WorkerProcess:run:TThreadPoolServer.java:310', 'java.util.concurrent.ThreadPoolExecutor:runWorker::-1', 'java.util.concurrent.ThreadPoolExecutor$Worker:run::-1', 'java.lang.Thread:run::-1', "*org.apache.spark.sql.catalyst.parser.ParseException:\n[PARSE_SYNTAX_ERROR] Syntax error at or near 'WHERE': extra input 'WHERE'.(line 17, pos 4)\n\n== SQL ==\n\n    CREATE OR REPLACE TABLE iceberg.aggr_warehouse.instruction_aggregate\n    USING parquet\n    AS\n    SELECT\n        inf.instruction_id,\n        c.course_id,\n        c.course_name,\n        ps.program_id,\n        ps.semester_name,\n        inf.num_student AS num_students,\n        inf.avg_final_score\n    FROM\n        iceberg.warehouse.instruction_fact inf\n    JOIN iceberg.warehouse.course c ON inf.course_id = c.course_id\n    JOIN iceberg.warehouse.program_semester ps ON inf.program_semester_id = ps.program_semester_id;\n    WHERE \n----^^^\n        inf.instruction_status = 'completed'\n    \n:48:13", 'org.apache.spark.sql.catalyst.parser.ParseException:withCommand:parsers.scala:257', 'org.apache.spark.sql.catalyst.parser.AbstractParser:parse:parsers.scala:98', 'org.apache.spark.sql.execution.SparkSqlParser:parse:SparkSqlParser.scala:54', 'org.apache.spark.sql.catalyst.parser.AbstractSqlParser:parsePlan:AbstractSqlParser.scala:68', 'org.apache.spark.sql.catalyst.parser.extensions.IcebergSparkSqlExtensionsParser:parsePlan:IcebergSparkSqlExtensionsParser.scala:126', 'org.apache.spark.sql.SparkSession:$anonfun$sql$5:SparkSession.scala:684', 'org.apache.spark.sql.catalyst.QueryPlanningTracker:measurePhase:QueryPlanningTracker.scala:138', 'org.apache.spark.sql.SparkSession:$anonfun$sql$4:SparkSession.scala:683', 'org.apache.spark.sql.SparkSession:withActive:SparkSession.scala:900', 'org.apache.spark.sql.SparkSession:sql:SparkSession.scala:682', 'org.apache.spark.sql.SparkSession:sql:SparkSession.scala:713', 'org.apache.spark.sql.SparkSession:sql:SparkSession.scala:744', 'org.apache.spark.sql.SQLContext:sql:SQLContext.scala:651', 'org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation:org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute:SparkExecuteStatementOperation.scala:227'], sqlState='42601', errorCode=0, errorMessage="Error running query: [PARSE_SYNTAX_ERROR] org.apache.spark.sql.catalyst.parser.ParseException: \n[PARSE_SYNTAX_ERROR] Syntax error at or near 'WHERE': extra input 'WHERE'.(line 17, pos 4)\n\n== SQL ==\n\n    CREATE OR REPLACE TABLE iceberg.aggr_warehouse.instruction_aggregate\n    USING parquet\n    AS\n    SELECT\n        inf.instruction_id,\n        c.course_id,\n        c.course_name,\n        ps.program_id,\n        ps.semester_name,\n        inf.num_student AS num_students,\n        inf.avg_final_score\n    FROM\n        iceberg.warehouse.instruction_fact inf\n    JOIN iceberg.warehouse.course c ON inf.course_id = c.course_id\n    JOIN iceberg.warehouse.program_semester ps ON inf.program_semester_id = ps.program_semester_id;\n    WHERE \n----^^^\n        inf.instruction_status = 'completed'\n    \n"), operationHandle=None); 4066)
[2024-12-13T18:55:00.974+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 1
[2024-12-13T18:55:01.038+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-12-13T18:55:01.047+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
